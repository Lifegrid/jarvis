from web_scraper.web_navigator import fetch_page_content
from web_scraper.page_reader import extract_main_content
from web_scraper.source_vectorizer import store_vector
from memory_engine.memory_search import search_memory

def test_scraping_flow():
    url = "https://fr.wikipedia.org/wiki/Intelligence_artificielle"
    
    print("ğŸŒ Ã‰tape 1 : RÃ©cupÃ©ration de la page...")
    html = fetch_page_content(url)
    assert "Intelligence artificielle" in html or "<html" in html.lower()
    print("âœ… Page rÃ©cupÃ©rÃ©e.")

    print("ğŸ“– Ã‰tape 2 : Extraction et rÃ©sumÃ© du contenu...")
    content = extract_main_content(html)
    print("ğŸ“„ RÃ©sumÃ© extrait :")
    print(content[:500] + "..." if len(content) > 500 else content)
    assert len(content) > 100

    print("ğŸ’¾ Ã‰tape 3 : Stockage vectoriel...")
    store_vector(url, content)
    print("âœ… StockÃ© dans la mÃ©moire.")

    print("ğŸ” Ã‰tape 4 : Recherche mÃ©moire...")
    results = search_memory("qu'est-ce que l'intelligence artificielle ?")
    print("ğŸ§  RÃ©sultats de recherche :")
    for doc in results:
        print("-", doc[:200].replace("\\n", " "), "...\n")

if __name__ == "__main__":
    test_scraping_flow()
