# core_llm/llm_stub.py

def mock_chat_response(prompt: str) -> str:
    if "comment tu t'appelles" in prompt.lower():
        return "Je suis Jarvis, ton assistant personnel !"
    elif "blague" in prompt.lower():
        return "Pourquoi les dÃ©veloppeurs nâ€™aiment pas la nature ? Parce quâ€™il y a trop de bugs ! ğŸ›"
    elif "gratins" in prompt.lower() or "chauffe" in prompt.lower():
        return "En gÃ©nÃ©ral, un gratin se rÃ©chauffe 15-20 minutes Ã  180Â°C dans un four prÃ©chauffÃ©."
    else:
        return "Hello! How can I help you today? If you have any questions or need assistance with something, feel free to ask."
