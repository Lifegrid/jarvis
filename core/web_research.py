# core/web_research.py

import requests
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
from core.llm_interface import ask_llm
from core.web_memory import store_web_memory, search_web_memory

def perform_web_research(query: str) -> str:
    """
    Fonction principale qui effectue une recherche intelligente sur le web.
    1. Cherche d'abord dans la m√©moire locale
    2. Si besoin, interroge DuckDuckGo
    3. R√©sume les r√©sultats de mani√®re utile
    """

    # 1. V√©rifie d'abord dans la m√©moire
    cached_result = search_web_memory(query)
    if cached_result:
        return f"(üß† R√©sultat de la m√©moire web)\n\n{cached_result}"

    # 2. Sinon, fait une vraie recherche web
    results = []
    try:
        with DDGS() as ddgs:
            results = ddgs.text(query, safesearch="Off", region="wt-wt", max_results=5)
    except Exception as e:
        return f"‚ùå Erreur recherche web : {str(e)}"

    if not results:
        return "‚ùå Aucun r√©sultat trouv√© sur Internet."

    # 3. R√©cup√®re les pages et extrait un peu de contenu
    snippets = []
    for r in results:
        url = r.get("href")
        if url:
            text = scrape_website_text(url)
            if text:
                snippets.append(f"- [{r.get('title', 'Lien')}]({url}) : {text[:300]}...")  # Limite √† 300 caract√®res

    if not snippets:
        return "‚ùå R√©sultats vides apr√®s scraping."

    # 4. Demande au LLM de r√©sumer intelligemment
    prompt = (
        "Voici des extraits de sites web trouv√©s pour la question suivante :\n"
        f"'{query}'\n\n"
        "Synth√©tise ces informations en une r√©ponse claire et concise, avec les points cl√©s :\n\n"
        + "\n".join(snippets)
    )

    final_summary = ask_llm([
        {"role": "system", "content": "Tu es un assistant personnel qui synth√©tise des recherches web de fa√ßon utile, fiable, concise."},
        {"role": "user", "content": prompt}
    ])

    # 5. Stocke la synth√®se dans la m√©moire
    store_web_memory(query, final_summary)

    return final_summary

def scrape_website_text(url: str) -> str:
    """
    Essaie d'extraire du texte lisible depuis un site web (HTML -> texte brut).
    """
    try:
        response = requests.get(url, timeout=5)
        soup = BeautifulSoup(response.text, "html.parser")

        # Retire les balises inutiles
        for script in soup(["script", "style", "header", "footer", "nav", "aside"]):
            script.decompose()

        text = soup.get_text(separator="\n")
        lines = [line.strip() for line in text.splitlines() if line.strip()]
        cleaned_text = "\n".join(lines)

        return cleaned_text[:2000]  # limite √† 2000 caract√®res max pour le traitement
    except Exception:
        return ""
